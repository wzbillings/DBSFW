{
  "hash": "a898bbdaacbbc76d9671148eac3a7893",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 19: From Hypothesis Testing to Parameter Estimation\"\ndraft: false\ncode-fold: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(\"scipen\" = 9999, \"digits\" = 4)\n```\n:::\n\n\n\n## Q1\n\n::: {.callout-note appearance=\"simple\"}\n\nOur Bayes factor assumed that we were looking at $H_1: P(\\text{prize} = 0.5)$.\nTHis allowed us to derive a version of the beta distribution with an alpha of 1\nand a beta of 1. Would it matter if we chose a different probability for $H_1$?\nAssume $H_1: P(\\text{prize} = 0.24)$, then see if the resulting distribution,\nonce normalized to sum to 1, is any different from the original hypothesis.\n\n:::\n\nOK, so what we need to do is calculate the new distribution and the old\ndistribution so we can compare them.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhypotheses <- seq(0, 1, by = 0.01)\nnumerator <- hypotheses ^ 24 * (1 - hypotheses) ^ 76\nbf_0.50 <- numerator / (0.50 ^ 24 * (1 - 0.50) ^ 76)\nbf_0.24 <- numerator / (0.24 ^ 24 * (1 - 0.24) ^ 76)\n\n# Now normalize the distributions\nbf_0.50_norm <- bf_0.50 / sum(bf_0.50)\nbf_0.24_norm <- bf_0.24 / sum(bf_0.24)\n\nplot(\n\tbf_0.24_norm, bf_0.50_norm,\n\txlab = \"Normalized Bayes factors when assumed probability = 0.24\",\n\tylab = \"Normalized Bayes factors when assumed probability = 0.50\",\n\tpch = 3, cex = 1.1\n)\nabline(a = 0, b = 1, lty = 2, col = \"gray\")\n```\n\n::: {.cell-output-display}\n![](cp19_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\nYou can see that the points are exactly correlated, i.e., the normalized\ndistributions are exactly the same.\n\n## Q2\n\n::: {.callout-note appearance=\"simple\"}\n\nWrite a prior for the distribution in which each hypothesis is 1.05 times more\nlikely than the previous hypothesis (assume our `dx` remains the same).\n\n:::\n\nFirst we'll create the prior.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- length(hypotheses)\nprior <- 1.05 ^ (0:(n-1))\n```\n:::\n\n\n\nTo obtain the posterior distribution, we multiply the priors by their\ncorresponding Bayes factors and normalize.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost_raw <- prior * bf_0.50_norm\npost <- post_raw / sum(post_raw)\nplot(\n\thypotheses, post, lwd = 3, type = \"l\",\n\txlab = \"Hypothesized prize probability\",\n\tylab = \"Normalized posterior density of result\"\n)\n```\n\n::: {.cell-output-display}\n![](cp19_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nWe can see that the best estimate is still around $0.24$. Even though the\nextreme values have higher prior likelihood, the evidence is strong enough\nto ignore them.\n\n\n## Q3\n\n::: {.callout-note appearance=\"simple\"}\n\nSuppose you observed another duck game that included 34 ducks with prizes and 66\nducks without prizes. How would you set up a test to answer \"What is the\nprobability that you have a better chance of winning a prize in this game than\nin the game we used in our example?\"\n\n:::\n\nIf we assume a $\\text{Beta}(1, 1)$ prior for both probabilities, then the\nposterior distribution for the probability of a prize in the first game is\n$\\text{Beta}(25, 77)$ and the posterior distribution for the probability of a\nprize in the second game is $\\text{Beta}(35, 67)$. We can conduct a Monte\nCarlo simulation with, say, $100,000$ draws from both distributions as we did\npreviously.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(132)\nn_sims <- 1e5\ngame_1_sim <- rbeta(n_sims, 25, 77)\ngame_2_sim <- rbeta(n_sims, 35, 67)\nprob <- mean(game_2_sim > game_1_sim)\n```\n:::\n\n\n\nFrom this simple simulation, the probability that we have a better chance of\nwinning a prize was about $93.9\\%$.\n\nApparently the solutions in the book wanted us to use arbitrary priors and use\na numerical algorithm to generate samples, but for a problem this simple I\ndoubt we will get different results unless we change the priors a lot.\n\n\n<!-- END OF FILE -->\n",
    "supporting": [
      "cp19_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}