---
title: "Chapter 8: Priors, posteriors, and likelihoods of Bayes' Theorem"
author: "Zane Billings"
date: "2022-12-09"
---

```{r setup}
options("scipen" = 9999, "digits" = 4)
```

This chapter is mostly about Bayes' factors without saying that it's about
Bayes factors, but it also discusses what happens when prior beliefs change
(in a particularly simple case). I personally don't think this chapter
generalizes very well to more complex analyses, but I guess the point of this
book is to be beginner-friendly. So maybe I'm at the point on my Bayes journey
where I am confident beyond what I actually know ¯\\_(ツ)_/¯.

# Notes

We'll return to the missing laptop example. Our goal for this example is
to calculate the relative posterior probability of our two hypotheses ($H_1:$
that we were robbed, and $H_2:$ that the kid has our laptop), that is:
$$B = \frac{P(H_1 \mid D)}{P(H_2 \mid D)}.$$

Now recall that Bayes' theorem is
$$P(H_i \mid D) = \frac{P(H_i)P(D \mid H_i)}{P(D)}.$$
Here, the LHS of the equation is the **posterior probability**. The $P(H_i)$ is
our **prior probability**, how likely we think the hypothesis is before we
observed any data. And we have the $P(D \mid H_i)$ part, which the book calls
the **likelihood**. I grew up frequentist and pedantic so I typically always
call this the ***sample*** **likelihood** or *the likelihood of the sample*.
Not sure why but I almost always use the latter, I think it just sounds nice.

Now, here are the probabilities the chapter gives us for the things we will
need to calculate the relative posterior probability (which the book calls
the relative likelihood, but I am strongly of the belief that likelihood
is a technical term and the posterior probabilities are not likelihoods).

\begin{align*}
P(H_1) &= \frac{1}{1000} \\
P(D \mid H_1) &= \frac{3}{10}  \\
P(H_2) &= \frac{1}{21,900,000}   \\
P(D \mid H_2) &= 1 
\end{align*}

So with this information we can calculate the relative posterior probability (
note that we can calculate the relative posterior probabilities but not the
individual posterior probabilities because the normalizing factors are unknown
to us) to get
$$B = \frac{3 / 10000}{1 / 21,900,000} = 6750. $$
So, given our data, it is 6750 times more likely that we were robbed.

## Q1

::: {.callout-note appearance="simple"}

As mentioned, you mighty disagree with the original probability assigned
to the likelihood:

$$P(\text{broken window, open front door, missing laptop} \mid \text{robbed}) = \frac{3}{10}.$$

**If we change this probability to $1/100$**, how does this change our strength in
believing $H_1$ over $H_2$?

:::

(I bolded the part that was supposed to be in the question but then wasn't.) If
we do this, it only changes the numerator of our ratio and we get that
$$B = \frac{3 / 100000}{1 / 21,900,000} = 657. $$
So this decreases our ratio by a factor of 10, the same amount that our beliefs
changed.

## Q2

::: {.callout-note appearance="simple"}

How unlikely would you have to believe being robbed is --- our prior for $H_1$
--- in order for the ratio of $H_1$ to $H_2$ to be one?

:::

Call our unknown prior probability $p$. Then we solve:
$$\frac{p \ \frac{3}{100}}{1 / 21,900,000} = 1 \implies p = \frac{1}{657,000}.$$
So in order for the ratio to be 1, we would need to believe that getting robbed
is 657 times less likely than the previous problem -- note that we could have
gotten the same answer by dividing our prior probability by the Bayes factor
from the previous problem.

<!-- end of file -->
